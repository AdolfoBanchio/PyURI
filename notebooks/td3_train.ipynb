{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538d4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "SRC_ROOT = \"../src\"\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7997151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from twc.twc_builder import build_twc\n",
    "from twc.twc_io import mcc_obs_encoder, twc_out_2_mcc_action\n",
    "from td3.td3_train import TD3Config, td3_train\n",
    "from td3.td3_engine import TD3Engine\n",
    "from utils import SequenceBuffer\n",
    "from mlp.MLP_models import Critic\n",
    "from utils.ou_noise import OUNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb762c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"MountainCarContinuous-v0\"\n",
    "SEED = 42\n",
    "TWC_INTERNAL_STEPS = 1\n",
    "CRITIC_HID_LAYERS = [400, 300]\n",
    "GAMMA              = 0.99\n",
    "TAU                = 5e-3\n",
    "ACTOR_LR           = 0.00028007729801810964\n",
    "CRITIC_LR          = 0.004320799314236164\n",
    "TARGET_POLICY_NOISE = 0.2\n",
    "TARGET_POLICY_CLIP = 0.5\n",
    "DEVICE             = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "td3_config = TD3Config()\n",
    "td3_config.max_episode = 2\n",
    "td3_config.use_bptt = True\n",
    "td3_config.sequence_length = 100\n",
    "td3_config.burn_in_length = 10\n",
    "td3_config.warmup_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4abb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"max_episode\": 2,\n",
      "    \"max_time_steps\": 999,\n",
      "    \"warmup_steps\": 1000,\n",
      "    \"batch_size\": 128,\n",
      "    \"num_update_loops\": 2,\n",
      "    \"policy_delay\": 1,\n",
      "    \"device\": \"cpu\",\n",
      "    \"eval_interval_episodes\": 10,\n",
      "    \"eval_episodes\": 10,\n",
      "    \"sigma_start\": 0.2,\n",
      "    \"sigma_end\": 0.05,\n",
      "    \"sigma_decay_episodes\": 100,\n",
      "    \"use_bptt\": true,\n",
      "    \"sequence_length\": 100,\n",
      "    \"burn_in_length\": 10,\n",
      "    \"best_model_prefix\": \"td3_actor_best\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(td3_config.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dda1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "env = gym.make(ENV)\n",
    "env.reset(seed=SEED)\n",
    "env.action_space.seed(SEED)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "actor = build_twc(obs_encoder=mcc_obs_encoder,\n",
    "                action_decoder=twc_out_2_mcc_action,\n",
    "                internal_steps=TWC_INTERNAL_STEPS,\n",
    "                log_stats=True)\n",
    "critic_1 = Critic(state_dim, action_dim, size=CRITIC_HID_LAYERS)\n",
    "critic_2 = Critic(state_dim, action_dim, size=CRITIC_HID_LAYERS)\n",
    "# --- CHANGED: Using SequenceBuffer ---\n",
    "buffer = SequenceBuffer(\n",
    "    capacity=100_000\n",
    ")\n",
    "ou_noise = OUNoise(action_dimension=env.action_space.shape[0],\n",
    "                mu=0,\n",
    "                theta=0.15,\n",
    "                sigma=td3_config.sigma_start,\n",
    "                sigma_end=td3_config.sigma_end,\n",
    "                sigma_decay_epis=td3_config.sigma_decay_episodes)\n",
    "actor_opt = torch.optim.Adam(actor.parameters(),  lr=ACTOR_LR)\n",
    "critic_opt = torch.optim.Adam(\n",
    "    itertools.chain(critic_1.parameters(), critic_2.parameters()),\n",
    "    lr=CRITIC_LR # Using the tuned LR from your params\n",
    ")\n",
    "td3 = TD3Engine(gamma=GAMMA,\n",
    "                tau=TAU,\n",
    "                observation_space=env.observation_space,\n",
    "                action_space=env.action_space,\n",
    "                actor=actor,\n",
    "                critic_1=critic_1,\n",
    "                critic_2=critic_2,\n",
    "                actor_optimizer=actor_opt,\n",
    "                critic_optimizer=critic_opt,\n",
    "                policy_delay=td3_config.policy_delay,\n",
    "                target_policy_noise=TARGET_POLICY_NOISE,\n",
    "                target_noise_clip=TARGET_POLICY_CLIP,\n",
    "                device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5266c0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('in_layer.threshold', tensor([0., 0., 0., 0.])), ('in_layer.decay', tensor([0.1000, 0.1000, 0.1000, 0.1000])), ('hid_layer.threshold', tensor([0., 0., 0., 0., 0.])), ('hid_layer.decay', tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000])), ('out_layer.threshold', tensor([0., 0.])), ('out_layer.decay', tensor([0.1000, 0.1000])), ('in2hid_IN.w', tensor([[ 0.8375,  0.9092, -0.2566,  1.0063, -0.2400],\n",
      "        [ 0.2211, -0.5333,  0.6433,  0.9657, -0.8036],\n",
      "        [ 0.9522,  0.2050,  0.8093,  0.1484,  0.5282],\n",
      "        [-0.1547,  0.8445,  0.1619, -0.5114,  0.2792]])), ('in2hid_IN.w_mask', tensor([[1., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.]])), ('in2hid_GJ.gj_w', tensor([ 0.4679, -0.2049])), ('in2hid_GJ.gj_idx', tensor([[1, 2],\n",
      "        [2, 1]])), ('hid_IN.w', tensor([[-0.5047, -0.1285, -0.4449,  0.7267, -0.8647],\n",
      "        [-0.5050, -0.3093, -0.6587,  0.1034, -1.0819],\n",
      "        [ 0.9893, -0.9305,  0.8457,  0.1823, -0.3557],\n",
      "        [ 0.6769,  0.1707,  0.8851,  0.1198, -0.3455],\n",
      "        [ 0.2943, -0.2971,  0.4610,  0.9780,  0.6332]])), ('hid_IN.w_mask', tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.]])), ('hid_EX.w', tensor([[-0.4789,  0.6324,  0.1960,  0.5563, -0.6677],\n",
      "        [-1.0844, -0.4232, -0.8402,  0.8989,  0.3155],\n",
      "        [ 0.4537,  0.3464, -0.0191,  0.8573, -0.7783],\n",
      "        [ 0.0690, -0.7477,  0.3378, -0.3773,  0.3357],\n",
      "        [-0.2282,  0.9086, -0.6493, -0.6533, -0.6534]])), ('hid_EX.w_mask', tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])), ('hid2out.w', tensor([[ 1.5579,  0.5772],\n",
      "        [ 1.6667, -1.4294],\n",
      "        [-1.7180, -1.3551],\n",
      "        [-1.1651,  0.7016],\n",
      "        [ 0.6202,  1.4392]])), ('hid2out.w_mask', tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]]))])\n"
     ]
    }
   ],
   "source": [
    "print(actor.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fd819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "actor.reset() # Reset stateful actor\n",
    "for _ in range(10_000):\n",
    "    action = env.action_space.sample()\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    buffer.store(obs, action, reward, next_obs, terminated, truncated)\n",
    "    obs = next_obs\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "        actor.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37982f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# --- Parameter & gradient inspection helpers ---\n",
    "def snapshot_params(module):\n",
    "    \"\"\"Return a dict name->tensor clone of parameters (cpu, detached).\"\"\"\n",
    "    return OrderedDict((name, p.detach().cpu().clone()) for name, p in module.named_parameters())\n",
    "\n",
    "def param_norm(t):\n",
    "    return t.norm().item()\n",
    "\n",
    "def print_param_changes(before, after, grads, top_k=20):\n",
    "    rows = []\n",
    "    for name in before.keys():\n",
    "        b = before[name]\n",
    "        a = after[name]\n",
    "        delta = (a - b)\n",
    "        delta_norm = delta.norm().item()\n",
    "        param_norm_val = b.norm().item()\n",
    "        # avoid division by zero\n",
    "        ratio = delta_norm / (param_norm_val + 1e-12)\n",
    "        grad_norm = grads.get(name).norm().item() if (name in grads and grads[name] is not None) else None\n",
    "        rows.append((name, param_norm_val, grad_norm, delta_norm, ratio))\n",
    "    # sort by absolute update magnitude\n",
    "    rows.sort(key=lambda r: r[3], reverse=True)\n",
    "    print(f\"{'param':60s} {'param_norm':>12s} {'grad_norm':>12s} {'delta_norm':>12s} {'update_ratio':>12s}\")\n",
    "    for name, pn, gn, dn, r in rows[:top_k]:\n",
    "        gn_s = f\"{gn:.3e}\" if gn is not None else \"None\"\n",
    "        print(f\"{name:60s} {pn:12.3e} {gn_s:12s} {dn:12.3e} {r:12.3e}\")\n",
    "    # summary stats\n",
    "    total_param = sum(r[1] for r in rows)\n",
    "    total_delta = sum(r[3] for r in rows)\n",
    "    print(f\"\\nTotal param norm: {total_param:.3e}, total update norm: {total_delta:.3e}, avg update ratio: {(total_delta/(total_param+1e-12)):.3e}\")\n",
    "\n",
    "# --- Register hooks and snapshot before update ---\n",
    "actor_device = next(actor.parameters()).device if any(True for _ in actor.parameters()) else torch.device(\"cpu\")\n",
    "# Clear any existing grads\n",
    "for p in actor.parameters():\n",
    "    if p.grad is not None:\n",
    "        p.grad.detach_()\n",
    "        p.grad.zero_()\n",
    "\n",
    "before = snapshot_params(actor)\n",
    "\n",
    "# Install hooks to capture gradients arriving at parameters during backward\n",
    "grad_captures = {}\n",
    "hook_handles = []\n",
    "for name, p in actor.named_parameters():\n",
    "    # define a closure capturing the name\n",
    "    def make_hook(n):\n",
    "        def hook(g):\n",
    "            # store a detached cpu clone of the grad tensor\n",
    "            grad_captures[n] = g.detach().cpu().clone() if g is not None else None\n",
    "        return hook\n",
    "    h = p.register_hook(make_hook(name))\n",
    "    hook_handles.append(h)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_name = f\"twc_td3_bptt_test_{timestamp}\" # Added _bptt\n",
    "log_dir = os.path.join(\"out\", \"runs\", run_name)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# --- Run the single BPTT update step (as you already do) ---\n",
    "td3_train(env=env,\n",
    "          engine=td3,\n",
    "          replay_buf=buffer,\n",
    "          ou_noise=ou_noise,\n",
    "          writer=writer,\n",
    "          config=td3_config,\n",
    "          timestamp=timestamp)\n",
    "\n",
    "# --- After the update: snapshot & report ---\n",
    "after = snapshot_params(actor)\n",
    "\n",
    "# Remove hooks\n",
    "for h in hook_handles:\n",
    "    try:\n",
    "        h.remove()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Print top parameter changes and gradient norms\n",
    "print_param_changes(before, after, grad_captures, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWC(\n",
      "  (in_layer): FIURIModule()\n",
      "  (hid_layer): FIURIModule()\n",
      "  (out_layer): FIURIModule()\n",
      "  (in2hid_IN): FiuriDenseConn()\n",
      "  (in2hid_GJ): FiuriSparseGJConn()\n",
      "  (hid_IN): FiuriDenseConn()\n",
      "  (hid_EX): FiuriDenseConn()\n",
      "  (hid2out): FiuriDenseConn()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c7ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Activation Analysis:\n",
      "\n",
      "in2hid_IN activation stats:\n",
      "shape: torch.Size([1, 5])\n",
      "mean: -3.96e+00\n",
      "std: 5.62e+00\n",
      "min: -1.20e+01\n",
      "max: -0.00e+00\n",
      "fraction of zeros: 60.00%\n",
      "\n",
      "6. Module Structure:\n",
      "\n",
      "in2hid_IN:\n",
      "Module type: FiuriDenseConn\n",
      "  Parameter 'w':\n",
      "    shape: torch.Size([4, 5])\n",
      "    stats: mean=3.01e-01, std=5.71e-01\n",
      "    requires_grad: True\n",
      "\n",
      "7. Network Path Analysis:\n",
      "\n",
      "Checking computational path for in2hid_IN.w:\n",
      "Has path to output: False\n",
      "Grad function type: UnsqueezeBackward0\n"
     ]
    }
   ],
   "source": [
    "# Let's trace the activation through the network\n",
    "test_obs = torch.randn(1, *env.observation_space.shape).to(DEVICE)\n",
    "actor.reset()\n",
    "\n",
    "# Enable activation tracking\n",
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output if not isinstance(output, tuple) else output[0]\n",
    "    return hook\n",
    "\n",
    "# Register forward hooks\n",
    "hooks = []\n",
    "for name, module in actor.named_modules():\n",
    "    if 'in2hid_IN' in name:  # Track the specific module we care about\n",
    "        h = module.register_forward_hook(get_activation(name))\n",
    "        hooks.append(h)\n",
    "\n",
    "# Run a forward pass\n",
    "with torch.set_grad_enabled(True):\n",
    "    out = actor(test_obs)\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "\n",
    "# Clean up hooks\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "# Check activation statistics\n",
    "print(\"\\n5. Activation Analysis:\")\n",
    "for name, act in activations.items():\n",
    "    if isinstance(act, torch.Tensor):\n",
    "        print(f\"\\n{name} activation stats:\")\n",
    "        print(f\"shape: {act.shape}\")\n",
    "        print(f\"mean: {act.mean().item():.2e}\")\n",
    "        print(f\"std: {act.std().item():.2e}\")\n",
    "        print(f\"min: {act.min().item():.2e}\")\n",
    "        print(f\"max: {act.max().item():.2e}\")\n",
    "        print(f\"fraction of zeros: {(act == 0).float().mean().item():.2%}\")\n",
    "\n",
    "# Let's also look at the module itself\n",
    "print(\"\\n6. Module Structure:\")\n",
    "for name, module in actor.named_modules():\n",
    "    if 'in2hid_IN' in name:\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Module type: {type(module).__name__}\")\n",
    "        for pname, param in module.named_parameters():\n",
    "            print(f\"  Parameter '{pname}':\")\n",
    "            print(f\"    shape: {param.shape}\")\n",
    "            print(f\"    stats: mean={param.mean().item():.2e}, std={param.std().item():.2e}\")\n",
    "            print(f\"    requires_grad: {param.requires_grad}\")\n",
    "\n",
    "# Examine the computational path\n",
    "print(\"\\n7. Network Path Analysis:\")\n",
    "def has_path_to_output(tensor, target, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if tensor is target:\n",
    "        return True\n",
    "    if not hasattr(tensor, 'grad_fn') or tensor in visited:\n",
    "        return False\n",
    "    visited.add(tensor)\n",
    "    if tensor.grad_fn is not None:\n",
    "        for next_tensor in tensor.grad_fn.next_functions:\n",
    "            if next_tensor[0] is not None:\n",
    "                if has_path_to_output(next_tensor[0], target, visited):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Find the in2hid_IN parameter in the computation\n",
    "found = False\n",
    "for name, p in actor.named_parameters():\n",
    "    if 'in2hid_IN' in name:\n",
    "        found = True\n",
    "        print(f\"\\nChecking computational path for {name}:\")\n",
    "        print(f\"Has path to output: {has_path_to_output(out, p)}\")\n",
    "        print(f\"Grad function type: {type(out.grad_fn).__name__ if out.grad_fn else None}\")\n",
    "        \n",
    "if not found:\n",
    "    print(\"Could not find in2hid_IN parameter!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyURI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
